DESCRIPTION
===========

The Multimodal Multisensor Activity Annotation Tool (MMAAT) allows for intuitive labeling of the data providing multiple viewports for visualizing data. The resulting supervised data can be exported for machine learning purposes.


Setup
-----

Install wheels from *http://www.lfd.uci.edu/~gohlke/pythonlibs/*

* install Python 2.7 (32-bit)
* install numpy
* install h5py
* install matplotlib
* install OpenCV 2.4
* install PyQt4
* install scipy

Ubuntu 16.04
------------

apt install python-numpy python-h5py python-matplotlib python-opencv python-pyqt5 python-scipy python-wheel

References
----------

Please cite the following [paper](https://dl.acm.org/citation.cfm?id=2971459) [(BibTeX)](https://dl.acm.org/downformats.cfm?id=2971459&parent_id=2968219&expformat=bibtex) if you use MMAAT:

```
@inproceedings{Barz:2016:MMA:2968219.2971459,
 author = {Barz, Michael and Moniri, Mohammad Mehdi and Weber, Markus and Sonntag, Daniel},
 title = {Multimodal Multisensor Activity Annotation Tool},
 booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct},
 series = {UbiComp '16},
 year = {2016},
 isbn = {978-1-4503-4462-3},
 location = {Heidelberg, Germany},
 pages = {17--20},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2968219.2971459},
 doi = {10.1145/2968219.2971459},
 acmid = {2971459},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data annotation, data capture, multimodal, multisensor},
} 

```
